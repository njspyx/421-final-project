{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ct-Y-LOqMIAm"
   },
   "source": [
    "# CMSC421 Final Project\n",
    "Team Members: Jordan Maggin, Lex Kim, Zhuo Cheng Xie, Neel Jay, Hylene Wu\n",
    "\n",
    "Project Description: The program will train on the set of images and gather information on airplanes from these images. With this information, it will attempt to both locate and identify airplanes in different sets of videos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JiLQOYwSG23"
   },
   "source": [
    "Importing dataset from Roboflow Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UyukieNxIhab",
    "outputId": "99a483dc-56e1-42de-c644-59d529b73830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GW\\Downloads\\421final\\datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file C:\\Users\\GW\\Downloads\\421final\\datasets already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "root_dir = os.getcwd()\n",
    "!mkdir {root_dir}\\datasets\n",
    "%cd {root_dir}\\datasets\n",
    "\n",
    "# paste the exported dataset code here\n",
    "!pip install roboflow --quiet\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"nr1RFEWRZXe3o3eQV1ns\")\n",
    "project = rf.workspace(\"cmsc421-final-project\").project(\"vehicle-detection-ansgq\")\n",
    "version = project.version(1)\n",
    "model = version.model\n",
    "dataset = version.download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpSsksiUWD1I"
   },
   "source": [
    "Custom Training\n",
    "\n",
    "(Weights are saved to /content/runs/detect/train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backend Functions\n",
    "\n",
    "Could be included in a Flask API if app is ever deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics==8.0.196 roboflow supervision --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# from ultralytics import YOLO\n",
    "from roboflow import Roboflow\n",
    "\n",
    "import supervision as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_KEY = \"nr1RFEWRZXe3o3eQV1ns\"\n",
    "API_KEY = \"WwDE4oQPlOhliOUfZFkn\"\n",
    "roboflow_workspace = \"cmsc421-final-project\"\n",
    "roboflow_project = \"plane-detection-eyzak\"\n",
    "version = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "def get_roboflow_model(workspace, project, version=1):\n",
    "    rf = Roboflow(api_key=API_KEY)\n",
    "    model = rf.workspace(workspace).project(project).version(version).model\n",
    "    return model\n",
    "model = get_roboflow_model(roboflow_workspace, roboflow_project, version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_image(model, image_path, output_path):    \n",
    "    bounding_box_annotator = sv.BoundingBoxAnnotator()\n",
    "    label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    pred = model.predict(image_path, confidence=0.5, overlap=0.5).json()\n",
    "    detections = sv.Detections.from_inference(pred)\n",
    "    \n",
    "    labels = [\n",
    "        f\"{class_name} {confidence:.2f}\"\n",
    "        for class_name, confidence\n",
    "        in zip(detections['class_name'], detections.confidence)\n",
    "    ]\n",
    "\n",
    "    annotated_image = bounding_box_annotator.annotate(\n",
    "        scene=image, detections=detections\n",
    "    )\n",
    "    \n",
    "    annotated_image = label_annotator.annotate(\n",
    "        annotated_image, detections=detections, labels=labels\n",
    "    )\n",
    "    \n",
    "    cv2.imwrite(output_path, annotated_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_video(model, video_path, output_path):\n",
    "    tracker = sv.ByteTrack()\n",
    "    bounding_box_annotator = sv.BoundingBoxAnnotator()\n",
    "    label_annotator = sv.LabelAnnotator()\n",
    "    trace_annotator = sv.TraceAnnotator(trace_length=80, thickness=3)\n",
    "    heat_map_annotator = sv.HeatMapAnnotator(radius=60, kernel_size=35)\n",
    "\n",
    "    video_info = sv.VideoInfo.from_video_path(video_path)\n",
    "    frames_generator = sv.get_video_frames_generator(video_path)\n",
    "    pred = None\n",
    "\n",
    "    with sv.VideoSink(output_path, video_info) as sink:\n",
    "        for i, frame in enumerate(frames_generator):\n",
    "#             print(f\"Frame {i}\")\n",
    "            if i % 20 == 0:\n",
    "                pred = model.predict(frame, confidence=0.5, overlap=0.5).json()\n",
    "\n",
    "            \"\"\"\n",
    "            detections = sv.Detections(\n",
    "                xyxy=pred['predictions'][0]['x'],\n",
    "                confidence=pred['predictions'][0]['confidence'],\n",
    "                class_id=pred['predictions'][0]['class']\n",
    "            )\n",
    "            \"\"\"\n",
    "            detections = sv.Detections.from_inference(pred)\n",
    "            detections = tracker.update_with_detections(detections)\n",
    "            labels = [\n",
    "                f\"{class_name} {confidence:.2f}\"\n",
    "                for class_name, confidence\n",
    "                in zip(detections['class_name'], detections.confidence)\n",
    "            ]\n",
    "\n",
    "            annotated_frame = bounding_box_annotator.annotate(\n",
    "                scene=frame.copy(), detections=detections\n",
    "            )\n",
    "            annotated_frame = label_annotator.annotate(\n",
    "                scene=annotated_frame, detections=detections, labels=labels\n",
    "            )\n",
    "            annotated_frame = trace_annotator.annotate(\n",
    "                scene=annotated_frame, detections=detections\n",
    "            )\n",
    "            annotated_frame = heat_map_annotator.annotate(\n",
    "                scene=annotated_frame, detections=detections\n",
    "            )\n",
    "\n",
    "            sink.write_frame(annotated_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example use\n",
    "# video_path = \"test_video.mov\"\n",
    "# output_path = \"annotated_video.mp4\"\n",
    "# annotate_video(model, video_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple GUI with PySimpleGUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pysimplegui in c:\\users\\gw\\anaconda3\\lib\\site-packages (5.0.4)\n",
      "Requirement already satisfied: rsa in c:\\users\\gw\\anaconda3\\lib\\site-packages (from pysimplegui) (4.7.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\gw\\anaconda3\\lib\\site-packages (from rsa->pysimplegui) (0.4.8)\n",
      "Requirement already satisfied: pillow in c:\\users\\gw\\appdata\\roaming\\python\\python311\\site-packages (10.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Installing PySimpleGUI\n",
    "!python -m pip install pysimplegui\n",
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import PySimpleGUI as sg\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/GW/Downloads/421final/datasets/Vehicle-Detection-1/valid/images\\prediction.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RuntimeWarning: invalid value encountered in divide\n",
      "RuntimeWarning: invalid value encountered in cast\n"
     ]
    }
   ],
   "source": [
    "# Defines potential filetypes to search for\n",
    "file_types = [(\"JPEG (*.jpg)\", \"*.jpg\"),\n",
    "              (\"All files (*.*)\", \"*.*\")]\n",
    "\n",
    "def main():\n",
    "    # Defines list of files from selected folder\n",
    "    file_list_column_img = [\n",
    "        [\n",
    "            sg.Text(\"Image Folder\"),\n",
    "            sg.In(size=(25, 1), enable_events=True, key=\"-IMG FOLDER-\"),\n",
    "            sg.FolderBrowse(),\n",
    "        ],\n",
    "        [\n",
    "            sg.Listbox(\n",
    "                values=[], enable_events=True, size=(60, 20), key=\"-IMG LIST-\"\n",
    "            )\n",
    "        ],\n",
    "    ]\n",
    "    \n",
    "    file_list_column_vid = [\n",
    "        [\n",
    "            sg.Text(\"Video Folder\"),\n",
    "            sg.In(size=(25, 1), enable_events=True, key=\"-VID FOLDER-\"),\n",
    "            sg.FolderBrowse(),\n",
    "        ],\n",
    "        [\n",
    "            sg.Listbox(\n",
    "                values=[], enable_events=True, size=(60, 20), key=\"-VID LIST-\"\n",
    "            )\n",
    "        ],\n",
    "    ]\n",
    "    \n",
    "    # Image display\n",
    "    image_display_column = [\n",
    "        [\n",
    "            sg.Image(key=\"-IMAGE-\"),\n",
    "        ]\n",
    "    ]\n",
    "    \n",
    "    # Video column -- lets user know if data has been processed or not.\n",
    "    vid_col = [\n",
    "        [\n",
    "            sg.Text(\"Press button once video is selected to process.\"),\n",
    "        ],\n",
    "        [\n",
    "#             sg.Text(),\n",
    "            sg.Text(\"Video not yet processed.\", size=(40, 1), key=\"-TOUT-\"),\n",
    "        ],\n",
    "        [\n",
    "            sg.Button(\"Process Video\"),\n",
    "        ]\n",
    "    ]\n",
    "    \n",
    "    # ----------------LAYOUTS\n",
    "    # Defines layout for the video processor\n",
    "    \n",
    "    layout_vid = [\n",
    "        [\n",
    "            sg.Column(file_list_column_vid, element_justification='c'),\n",
    "            sg.VSeparator(),\n",
    "            sg.Column(vid_col, element_justification='c')\n",
    "        ],\n",
    "    ]\n",
    "    \n",
    "    # Defines layout for image viewer\n",
    "    layout_img = [\n",
    "        #[sg.Image(key=\"-IMAGE-\")],\n",
    "        [\n",
    "            sg.Column(file_list_column_img, element_justification='c'),\n",
    "            sg.VSeparator(),\n",
    "            sg.Column(image_display_column, element_justification='c'),\n",
    "        ],\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    layout = [\n",
    "        [\n",
    "            sg.Column(layout_img, key='-COL1-'), sg.Column(layout_vid, visible=False, key='-COL2-')\n",
    "        ],\n",
    "        [\n",
    "            sg.Button(\"Swap Program\")\n",
    "        ],\n",
    "        [\n",
    "            sg.Button(\"Exit Program\")\n",
    "        ],\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # Applies the layout to the window\n",
    "    window = sg.Window(\"CMSC421 Computer Vision // Final Project\", layout, element_justification='c')\n",
    "    layout = 1\n",
    "    \n",
    "    ###########\n",
    "    # UPDATER #\n",
    "    ###########\n",
    "    # Updates the window with corresponding values and images\n",
    "    while True:\n",
    "        event, values = window.read()\n",
    "        \n",
    "        # Closes the window upon pressing the Exit button or closing the window.\n",
    "        if event == \"Exit Program\" or event == sg.WIN_CLOSED:\n",
    "            break\n",
    "        # Swaps program\n",
    "        if event == \"Swap Program\":\n",
    "            window[f'-COL{layout}-'].update(visible=False)\n",
    "            if layout == 1:\n",
    "                layout = 2\n",
    "            else:\n",
    "                layout = 1\n",
    "            window[f'-COL{layout}-'].update(visible=True)\n",
    "                    \n",
    "        # Events for IMG\n",
    "        if event == \"-IMG FOLDER-\":\n",
    "            folder = values[\"-IMG FOLDER-\"]\n",
    "            try:\n",
    "                # Get list of files in folder\n",
    "                file_list = os.listdir(folder)\n",
    "            except:\n",
    "                file_list = []\n",
    "\n",
    "            fnames = [\n",
    "                f\n",
    "                for f in file_list\n",
    "                if os.path.isfile(os.path.join(folder, f))\n",
    "                and f.lower().endswith((\".jpg\"))\n",
    "            ]\n",
    "            window[\"-IMG LIST-\"].update(fnames)\n",
    "        if event == \"-IMG LIST-\":  # A file was chosen from the listbox\n",
    "            try:\n",
    "                filename_input = os.path.join(\n",
    "                    values[\"-IMG FOLDER-\"], values[\"-IMG LIST-\"][0]\n",
    "                )\n",
    "                \n",
    "                filename_output = os.path.join(\n",
    "                    values[\"-IMG FOLDER-\"], 'prediction.jpg'\n",
    "                )\n",
    "\n",
    "                annotate_image(model,filename_input,filename_output)\n",
    "                image = Image.open(filename_output)\n",
    "                image.thumbnail((400, 400))\n",
    "                bio = io.BytesIO()\n",
    "                image.save(bio, format=\"PNG\")\n",
    "                window[\"-IMAGE-\"].update(data=bio.getvalue())\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        # Events for VID\n",
    "        if event == \"-VID FOLDER-\":\n",
    "            folder = values[\"-VID FOLDER-\"]\n",
    "            try:\n",
    "                # Get list of files in folder\n",
    "                file_list = os.listdir(folder)\n",
    "            except:\n",
    "                file_list = []\n",
    "\n",
    "            fnames = [\n",
    "                f\n",
    "                for f in file_list\n",
    "                if os.path.isfile(os.path.join(folder, f))\n",
    "                and f.lower().endswith((\".mov\"))\n",
    "            ]\n",
    "            window[\"-VID LIST-\"].update(fnames)\n",
    "        if event == \"-VID LIST-\":  # A file was chosen from the listbox\n",
    "            try:\n",
    "                pass\n",
    "#                 filename_input = os.path.join(\n",
    "#                     values[\"-VID FOLDER-\"], values[\"-VID LIST-\"][0]\n",
    "#                 )\n",
    "                \n",
    "#                 filename_output = os.path.join(\n",
    "#                     values[\"-VID FOLDER-\"], 'prediction.mp4'\n",
    "#                 )\n",
    "#                 window[\"-TOUT-\"].update(\"Video processed.\")\n",
    "                \n",
    "#                 annotate_video(model,filename_input,filename_output)\n",
    "            except:\n",
    "                pass\n",
    "        if event == \"Process Video\":\n",
    "            try:\n",
    "                pass\n",
    "                filename_input = os.path.join(\n",
    "                    values[\"-VID FOLDER-\"], values[\"-VID LIST-\"][0]\n",
    "                )\n",
    "                \n",
    "                filename_output = os.path.join(\n",
    "                    values[\"-VID FOLDER-\"], 'prediction.mp4'\n",
    "                )\n",
    "                window[\"-TOUT-\"].update(\"Video processed.\")\n",
    "                \n",
    "                annotate_video(model,filename_input,filename_output)\n",
    "            except:\n",
    "                pass\n",
    "#         if event == \"Load Image\":  # NOTE: This part is currently unused, but is available for debugging.\n",
    "#             filename = values[\"-FILE-\"]\n",
    "#             if os.path.exists(filename):\n",
    "#                 # NOTE: If you want to do predictions, they would have to be placed here, prior to conversion.\n",
    "#                 image = Image.open(values[\"-FILE-\"])\n",
    "#                 image.thumbnail((400, 400))\n",
    "#                 bio = io.BytesIO()\n",
    "#                 image.save(bio, format=\"PNG\")\n",
    "#                 window[\"-IMAGE-\"].update(data=bio.getvalue())\n",
    "    \n",
    "    # Closes window after break\n",
    "    window.close()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
